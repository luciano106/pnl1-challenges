# ğŸ§  DesafÃ­os de Procesamiento del Lenguaje Natural (PNL1)

![Estado](https://img.shields.io/badge/Estado-Completado-00b894)
![Google Colab](https://img.shields.io/badge/Google%20Colab-Disponible-orange)
![Licencia](https://img.shields.io/badge/Licencia-MIT-blue)

Este repositorio agrupa los trabajos prÃ¡cticos desarrollados como parte del curso **Procesamiento del Lenguaje Natural (PNL1)**. Cada notebook aborda una tÃ©cnica distinta del PLN, desde modelos estadÃ­sticos hasta enfoques neuronales y bots conversacionales.

---

## ğŸ” DesafÃ­os Realizados

---

![Naive Bayes](https://upload.wikimedia.org/wikipedia/commons/thumb/9/99/Naive_Bayes.png/640px-Naive_Bayes.png)

### 1ï¸âƒ£ ClasificaciÃ³n de textos con NaÃ¯ve Bayes

**Objetivo:**  
Implementar un modelo de clasificaciÃ³n de texto utilizando el algoritmo NaÃ¯ve Bayes sobre el dataset *20 Newsgroups*.  
Se realizÃ³ la vectorizaciÃ³n del texto mediante tÃ©cnicas de bolsa de palabras y TF-IDF, seguida de la evaluaciÃ³n del clasificador en tareas de detecciÃ³n de tÃ³picos.

ğŸ“ [Abrir en Colab](https://colab.research.google.com/drive/ID_DEL_NOTEBOOK_1)

---

![Word2Vec](https://jalammar.github.io/images/word2vec/word2vec-embedding-space.png)

### 2ï¸âƒ£ Word2Vec entrenado con Don Quijote

**Objetivo:**  
El objetivo de este trabajo fue crear vectores de palabras utilizando **Word2Vec de Gensim**, entrenados sobre el texto completo de *Don Quijote de la Mancha*.  
Se aplicaron tÃ©cnicas de preprocesamiento con spaCy para tokenizar y limpiar el corpus, seguido de una exploraciÃ³n del espacio de embeddings en 2D y 3D mediante PCA y t-SNE.  
Se analizaron relaciones semÃ¡nticas entre tÃ©rminos del universo narrativo de la obra, observando agrupamientos y proximidades contextuales.

ğŸ“ [Abrir en Colab](https://colab.research.google.com/drive/ID_DEL_NOTEBOOK_2)

---

![Char RNN](https://miro.medium.com/v2/resize:fit:800/format:webp/1*iF1Wcb8vth5K-Iw4FnGqkA.png)

### 3ï¸âƒ£ Modelo de Lenguaje basado en Caracteres (RNN)

**Objetivo:**  
Implementar un modelo de lenguaje secuencial utilizando redes neuronales recurrentes (SimpleRNN, LSTM o GRU), entrenado a nivel de **caracteres**.  
El modelo fue entrenado para predecir la siguiente secuencia dada una secuencia de entrada, respetando la estructura many-to-many.  
Se utilizÃ³ `rmsprop` como optimizador y se evaluÃ³ el rendimiento mediante perplejidad.  
Se generaron textos utilizando greedy search, beam search determinÃ­stico y estocÃ¡stico, analizando el impacto de la **temperatura** sobre la diversidad del texto generado.

ğŸ“ [Abrir en Colab](https://colab.research.google.com/drive/ID_DEL_NOTEBOOK_3)

---

![Chatbot](https://jalammar.github.io/images/transformer/transformer-chatbot.png)

### 4ï¸âƒ£ Bot conversacional con datos de ConvAI2

**Objetivo:**  
Construir un BOT conversacional basado en el dataset **ConvAI2 (Conversational Intelligence Challenge 2)**, orientado a tareas de preguntas y respuestas (QA).  
Este primer prototipo del bot utiliza conversaciones en inglÃ©s para aprender patrones de diÃ¡logo y brindar respuestas relevantes al usuario, estableciendo las bases para una arquitectura de diÃ¡logo mÃ¡s compleja.

ğŸ“ [Abrir en Colab](https://colab.research.google.com/drive/ID_DEL_NOTEBOOK_4)

---

## ğŸ“ Notas

- Todos los notebooks estÃ¡n diseÃ±ados para ejecutarse directamente en Google Colab.
- Asegurate de tener conexiÃ³n a internet y una cuenta de Google para acceder y guardar una copia (`Archivo > Guardar una copia en Drive`).
- Las imÃ¡genes utilizadas son representativas de los temas tratados y sirven como apoyo visual.

---

## ğŸ§‘â€ğŸ’» Autor

**Nombre:** [Tu Nombre]  
**Email:** [tu.email@ejemplo.com]  
**InstituciÃ³n:** Universidad de Buenos Aires  
**Curso:** Procesamiento del Lenguaje Natural (PNL1) â€“ 2025
